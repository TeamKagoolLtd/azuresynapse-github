{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "synw-poc-esu2-01"
		},
		"LS_ADLsgen2_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'LS_ADLsgen2'"
		},
		"synw-poc-esu2-01-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'synw-poc-esu2-01-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:synw-poc-esu2-01.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"synw-poc-esu2-01-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://adoadlsdev.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/LS_ADLsgen2')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"connectionString": "[parameters('LS_ADLsgen2_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/synw-poc-esu2-01-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('synw-poc-esu2-01-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/synw-poc-esu2-01-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('synw-poc-esu2-01-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Trigger 1')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Week",
						"interval": 15,
						"startTime": "2022-11-07T18:06:00Z",
						"timeZone": "UTC"
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Trigger 2')]",
			"type": "Microsoft.Synapse/workspaces/triggers",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"runtimeState": "Stopped",
				"pipelines": [],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Week",
						"interval": 15,
						"startTime": "2022-11-07T18:06:00Z",
						"timeZone": "UTC"
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 3')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "select * DATETIME2FROMPARTS",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TestSQL01')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT * FROM spt_monitor",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 1')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "15152bc7-3227-41a7-a27c-7dfbc6eb37c4"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql import SparkSession - Rajesh\r\n",
							"from pyspark.sql.types import * \r\n",
							"\r\n",
							"# Azure storage access info \r\n",
							"blob_account_name = 'Your blob name' # replace with your blob name \r\n",
							"blob_container_name = 'Your container name' # replace with your container name \r\n",
							"blob_relative_path = 'Your relative path' # replace with your relative folder path \r\n",
							"linked_service_name = 'Your linked service name' # replace with your linked service name \r\n",
							"\r\n",
							"blob_sas_token = mssparkutils.credentials.getConnectionStringOrCreds(linked_service_name) \r\n",
							"\r\n",
							"# Allow SPARK to access from Blob remotely \r\n",
							"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path) \r\n",
							"spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name), blob_sas_token) \r\n",
							"print('Remote blob path: ' + wasbs_path) \r\n",
							"\r\n",
							"data = spark.range(5,10) \r\n",
							"\r\n",
							"# Write spark dataframe as a csv file \r\n",
							"csv_path = wasbs_path + 'Your file name ' \r\n",
							"data.write.csv(csv_path, mode = 'overwrite', header = 'true') \r\n",
							"\r\n",
							"# Write spark dataframe as a parquet file \r\n",
							"parquet_path = wasbs_path + ' Your file name ' \r\n",
							"data.write.parquet(parquet_path, mode = 'overwrite') \r\n",
							"\r\n",
							"# Write spark dataframe as a json file \r\n",
							"json_path = wasbs_path + 'Your file name ' \r\n",
							"data.write.json(json_path, mode = 'overwrite')"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 2')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "01d5e141-78a7-4fd0-a895-bf6541b81ebb"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"delta_table.history().show(20, 1000, False)\r\n",
							"from pyspark.sql import SparkSession \r\n",
							"# Azure storage access info \r\n",
							"\r\n",
							"blob_account_name = 'Your account name' # replace with your blob name \r\n",
							"blob_container_name = 'Your container name' # replace with your container name \r\n",
							"blob_relative_path = 'Your path' # replace with your relative folder path \r\n",
							"linked_service_name = 'Your linked service name' # replace with your linked service name \r\n",
							"\r\n",
							"blob_sas_token = mssparkutils.credentials.getConnectionStringOrCreds(linked_service_name) \r\n",
							"\r\n",
							"# Allow SPARK to access from Blob remotely \r\n",
							"\r\n",
							"wasb_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path) \r\n",
							"spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name), blob_sas_token) \r\n",
							"print('Remote blob path: ' + wasb_path) "
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 3')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "2baddce5-fce0-403b-a51f-d7ec8b2b3218"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql import SparkSession \r\n",
							"from pyspark.sql.types import * \r\n",
							"\r\n",
							"# Primary storage info \r\n",
							"account_name = 'Your primary storage account name' # fill in your primary account name \r\n",
							"container_name = 'Your container name' # fill in your container name \r\n",
							"relative_path = 'Your relative path' # fill in your relative folder path \r\n",
							"\r\n",
							"adls_path = 'abfss://%s@%s.dfs.core.windows.net/%s' % (container_name, account_name, relative_path) \r\n",
							"print('Primary storage account path: ' + adls_path) \r\n",
							"\r\n",
							"data = spark.range(5,10) \r\n",
							"\r\n",
							"# Write spark dataframe as a csv file \r\n",
							"csv_path = adls_path + 'Your file name ' \r\n",
							"data.write.csv(csv_path, mode = 'overwrite', header = 'true') \r\n",
							"\r\n",
							"# Write spark dataframe as a parquet file \r\n",
							"parquet_path = adls_path + ' Your file name ' \r\n",
							"data.write.parquet(parquet_path, mode = 'overwrite') \r\n",
							"\r\n",
							"# Write spark dataframe as a json file \r\n",
							"json_path = adls_path + 'Your file name ' \r\n",
							"data.write.json(json_path, mode = 'overwrite')"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 4')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "ce7700e1-8dfb-402f-b305-d7bc2cc71cb2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql import SparkSession \r\n",
							"# Azure storage access info \r\n",
							"\r\n",
							"blob_account_name = 'Your account name' # replace with your blob name \r\n",
							"blob_container_name = 'Your container name' # replace with your container name \r\n",
							"blob_relative_path = 'Your path' # replace with your relative folder path \r\n",
							"linked_service_name = 'Your linked service name' # replace with your linked service name \r\n",
							"\r\n",
							"blob_sas_token = mssparkutils.credentials.getConnectionStringOrCreds(linked_service_name) \r\n",
							"\r\n",
							"# Allow SPARK to access from Blob remotely \r\n",
							"\r\n",
							"wasb_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path) \r\n",
							"spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name), blob_sas_token) \r\n",
							"print('Remote blob path: ' + wasb_path) "
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		}
	]
}